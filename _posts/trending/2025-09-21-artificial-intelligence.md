---
layout: default
title: "What is Artificial Intelligence?"
date: 2025-09-21
categories: [Trending]
tags: [Artificial, Intelligence, Trending]
author: Rakesh Tyata
---

# <span style="color:#1f77b4;">Artificial Intelligence (AI)</span>

**Goal:** Make machines "intelligent" (simulate human decision-making)  
**Applications:** Chatbots, self-driving cars, recommendation systems

---

## <span style="color:#ff7f0e;">Machine Learning (ML)</span>

### <span style="color:#2ca02c;">Supervised Learning</span>

- **Concept:** Learn from labeled data
- **Types / Algorithms:** Regression (Linear, Logistic), Decision Trees, SVM, kNN
- **Examples:** Predicting house prices, spam detection

### <span style="color:#d62728;">Unsupervised Learning</span>

- **Concept:** Find patterns without labels
- **Types / Algorithms:** Clustering (K-Means, Hierarchical), Dimensionality Reduction (PCA, t-SNE), Anomaly Detection
- **Examples:** Customer segmentation, fraud detection

---

## <span style="color:#17becf;">Neural Networks (NN)</span>

- **Concept:** Algorithms inspired by the brain
- **Types:** Feedforward NN, CNN, RNN (LSTM, GRU)
- **Examples:** Handwriting recognition, image classification

### <span style="color:#1f77b4;">Deep Learning (DL)</span>

- **Concept:** Neural networks with many layers
- **Types:** CNN (images), RNN / LSTM / GRU (sequences), Transformers (text), Autoencoders
- **Examples:** Face recognition, voice assistants, GPT models

---

## <span style="color:#ff7f0e;">Reinforcement Learning (RL)</span>

- **Concept:** Learn by trial & error using rewards
- **Types:** Value-based (Q-Learning, SARSA), Policy-based (Policy Gradient), Actor-Critic
- **Terminology:** Agent, Environment, State, Action, Reward, Inference
- **Examples:** AlphaGo, robot navigation, Deep RL using neural networks

---

### <span style="color:#2ca02c;">Key Notes</span>

- **Training:** Learning patterns from data.
- **Inference:** Applying learned patterns to make predictions.
- **Activation Function:** Decides if a neuron should fire or pass its signal forward.
- **Loss Function:** The difference between the expected (true) output and the model’s predicted output.
- **Epoch:** One full pass of training data through the model.
- **Overfitting:** When a model memorizes training data and fails on new data.
- **Underfitting:** When a model is too simple and cannot capture the underlying patterns.
- **Bias:** A parameter that allows the model to shift the activation function.
- **Dropout:** Randomly turning off neurons during training to improve generalization.
- **Gradient:** The derivative of the loss function w.r.t model parameters, used to update weights.
- **Optimizer:** Algorithm that adjusts the model’s weights to minimize the loss (e.g., SGD, Adam).

```
Artificial Intelligence (AI)
 ├── Goal: Make machines "intelligent" (simulate human decision-making)
 ├── Applications: Chatbots, self-driving cars, recommendation systems
 └── Machine Learning (ML) - Machines learn patterns from data without explicit programming
      ├── Supervised Learning - Learn from labeled examples to predict outcomes
      │     ├── Concept: Learn from labeled data
      │     ├── Types / Algorithms:
      │     │     ├── Regression (Linear, Logistic) - Predict continuous or categorical outcomes
      │     │     ├── Decision Trees - Split data for predictions
      │     │     ├── SVM - Classify with hyperplanes
      │     │     └── kNN - Classify based on nearest neighbors
      │     └── Examples: Predicting house prices, spam detection
      │
      ├── Unsupervised Learning - Discover hidden patterns in unlabeled data
      │     ├── Concept: Find patterns without labels
      │     ├── Types / Algorithms:
      │     │     ├── Clustering (K-Means, Hierarchical) - Group similar data
      │     │     ├── Dimensionality Reduction (PCA, t-SNE) - Reduce features
      │     │     └── Anomaly Detection - Detect unusual data points
      │     └── Examples: Customer segmentation, fraud detection
      │
      ├── Neural Networks (NN) - Models inspired by the brain for pattern recognition
      │     ├── Concept: Algorithms inspired by the brain
      │     ├── Types:
      │     │     ├── Feedforward NN - Basic layered network
      │     │     ├── CNN - Processes images
      │     │     └── RNN (LSTM, GRU) - Processes sequences
      │     └── Examples: Handwriting recognition, image classification
      │
      ├── Deep Learning (DL) - Neural networks with many layers for complex patterns
      │     ├── Concept: Neural networks with many layers
      │     ├── Types:
      │     │     ├── CNN (images)
      │     │     ├── RNN / LSTM / GRU (sequences)
      │     │     ├── Transformers (text)
      │     │     └── Autoencoders (compress data)
      │     └── Examples: Face recognition, voice assistants, GPT models
      │
      └── Reinforcement Learning (RL) - Learn by trial and error with rewards
            ├── Concept: Learn by trial & error using rewards
            ├── Types:
            │     ├── Value-based (Q-Learning, SARSA) - Learn state values
            │     ├── Policy-based (Policy Gradient) - Learn action policies
            │     └── Actor-Critic - Combines both approaches
            └── Examples: AlphaGo, robot navigation, Deep RL using neural networks
```
